{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8XgqYfiVNGW",
        "outputId": "53d29bbd-f515-4418-c70e-1c9e036de3f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   customer_id     name region  order_id  amount      _merge\n",
            "0            1    Alice   East     101.0    50.0        both\n",
            "1            2      Bob   West     102.0   120.0        both\n",
            "2            2      Bob   West     103.0    80.0        both\n",
            "3            3  Charlie   East     105.0    90.0        both\n",
            "4            4    David  South       NaN     NaN   left_only\n",
            "5            5      NaN    NaN     104.0    30.0  right_only\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example DataFrames\n",
        "customers = pd.DataFrame({\n",
        "    'customer_id': [1, 2, 3, 4],\n",
        "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'region': ['East', 'West', 'East', 'South']\n",
        "})\n",
        "\n",
        "orders = pd.DataFrame({\n",
        "    'order_id': [101, 102, 103, 104, 105],\n",
        "    'customer_id': [1, 2, 2, 5, 3],\n",
        "    'amount': [50.0, 120.0, 80.0, 30.0, 90.0]\n",
        "})\n",
        "\n",
        "\n",
        "merged_df = pd.merge(customers, orders,\n",
        "                     on='customer_id',\n",
        "                     how='outer',\n",
        "                     indicator=True) \n",
        "\n",
        "print(merged_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7zVHK9VVO4F",
        "outputId": "ef3c0024-6f78-49cf-9ff0-f0c4038c8eeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   customer_id     name region  order_id  amount\n",
            "0            1    Alice   East       101    50.0\n",
            "1            2      Bob   West       102   120.0\n",
            "2            2      Bob   West       103    80.0\n",
            "3            5      NaN    NaN       104    30.0\n",
            "4            3  Charlie   East       105    90.0\n"
          ]
        }
      ],
      "source": [
        "from os.path import join\n",
        "import pandas as pd\n",
        "\n",
        "customers = pd.DataFrame({\n",
        "    \"customer_id\": [1, 2, 3, 4],\n",
        "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
        "    \"region\": [\"East\", \"West\", \"East\", \"South\"]\n",
        "})\n",
        "\n",
        "orders = pd.DataFrame({\n",
        "    \"order_id\": [101, 102, 103, 104, 105],\n",
        "    \"customer_id\": [1, 2, 2, 5, 3],\n",
        "    \"amount\": [50.0, 120.0, 80.0, 30.0, 90.0]\n",
        "})\n",
        "\n",
        "join_df = customers.set_index(\"customer_id\").join(\n",
        "    orders.set_index(\"customer_id\"),\n",
        "    how=\"right\"\n",
        ").reset_index()\n",
        "\n",
        "print(join_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_c9mdGkW-YX",
        "outputId": "4413efb1-45a9-4eeb-a3ed-6e4aa46d0698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Product    A   B\n",
            "Month           \n",
            "1        100  50\n",
            "2        110  60\n",
            "3        150  70\n"
          ]
        }
      ],
      "source": [
        "# Data prepared for pivoting: Sales by Product and Month\n",
        "data = {\n",
        "    'Month': [1, 1, 2, 2, 3, 3],\n",
        "    'Product': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
        "    'Sales': [100, 50, 110, 60, 150, 70]\n",
        "}\n",
        "df_sales = pd.DataFrame(data)\n",
        "\n",
        "# Pivot: Turn products into columns, aggregated by month\n",
        "pivoted_df = df_sales.pivot_table(\n",
        "    index='Month',\n",
        "    columns='Product',\n",
        "    values='Sales',\n",
        "    aggfunc='sum'\n",
        ")\n",
        "\n",
        "print(pivoted_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ide_ECqtYe0w",
        "outputId": "38e1b31d-a0e1-4757-f06a-aecb48e6205b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Month Product  Sales\n",
            "0      1       A    100\n",
            "1      2       A    110\n",
            "2      3       A    150\n",
            "3      1       B     50\n",
            "4      2       B     60\n",
            "5      3       B     70\n"
          ]
        }
      ],
      "source": [
        "# Melting the pivoted_df back into a long format\n",
        "melted_df = pd.melt(pivoted_df.reset_index(),\n",
        "                    id_vars=['Month'],\n",
        "                    value_vars=['A', 'B'],\n",
        "                    var_name='Product',\n",
        "                    value_name='Sales')\n",
        "\n",
        "print(melted_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3gD2xOaYpOa",
        "outputId": "5f22abc3-58d0-4147-8534-115d8b67e543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized (Min-Max):\n",
            "[[0.   0.  ]\n",
            " [0.5  0.44]\n",
            " [1.   1.  ]]\n",
            "\n",
            "Standardized (Z-Score):\n",
            "[[-1.22 -1.18]\n",
            " [ 0.   -0.09]\n",
            " [ 1.22  1.27]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "data = np.array([[10, 1], [20, 5], [30, 10]])\n",
        "\n",
        "# 1. Normalization (MinMaxScaler)\n",
        "scaler_norm = MinMaxScaler()\n",
        "data_normalized = scaler_norm.fit_transform(data)\n",
        "print('Normalized (Min-Max):')\n",
        "print(data_normalized.round(2))\n",
        "\n",
        "# 2. Standardization (StandardScaler)\n",
        "scaler_std = StandardScaler()\n",
        "data_standardized = scaler_std.fit_transform(data)\n",
        "print('\\nStandardized (Z-Score):')\n",
        "print(data_standardized.round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irqWFN22mZRh",
        "outputId": "8969c131-794f-4401-94ed-4b33f941c43f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Dtypes:\n",
            "A      int64\n",
            "B    float64\n",
            "C        str\n",
            "D        str\n",
            "dtype: object\n",
            "Original Memory Usage: 0.00 MB\n",
            "Optimized Dtypes:\n",
            "A        int8\n",
            "B     float32\n",
            "C    category\n",
            "D         str\n",
            "dtype: object\n",
            "Optimized Memory Usage: 0.00 MB\n"
          ]
        }
      ],
      "source": [
        "# 1. Optimizing Integer and Float Types\n",
        "\n",
        "def downcast_numeric(df):\n",
        "    for col in df.select_dtypes(include=['int64', 'float64']).columns:\n",
        "        # Check limits and downcast to the smallest fit\n",
        "        if 'int' in str(df[col].dtype):\n",
        "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
        "        elif 'float' in str(df[col].dtype):\n",
        "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
        "    return df\n",
        "\n",
        "# Create a sample DataFrame for demonstration\n",
        "import pandas as pd\n",
        "data = {\n",
        "    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'B': [1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8, 9.9, 10.1],\n",
        "    'C': ['apple', 'banana', 'apple', 'orange', 'banana', 'apple', 'grape', 'orange', 'banana', 'apple'],\n",
        "    'D': ['long string data', 'more long string data', 'long string data', 'unique string', 'more long string data', 'long string data', 'some other text', 'unique string', 'more long string data', 'long string data']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original Dtypes:\")\n",
        "print(df.dtypes)\n",
        "print(f\"Original Memory Usage: {df.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")\n",
        "\n",
        "# 2. Optimizing String Types (Critical for low-cardinality data)\n",
        "\n",
        "# Column 'C' has only 5 unique values (low cardinality)\n",
        "df['C'] = df['C'].astype('category')\n",
        "\n",
        "df_optimized = downcast_numeric(df.copy())\n",
        "\n",
        "# Re-check memory usage\n",
        "optimized_mem = df_optimized.memory_usage(deep=True).sum() / (1024**2)\n",
        "\n",
        "print('Optimized Dtypes:')\n",
        "print(df_optimized.dtypes)\n",
        "print(f\"Optimized Memory Usage: {optimized_mem:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrZiN1OXmZqt",
        "outputId": "a9589f92-b70c-4230-bdce-e53c417f0bce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline training successful.\n",
            "\n",
            "Predictions on new data: [0 1]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Sample Data (Simulating raw input)\n",
        "data = {\n",
        "    'Age': [30, 45, np.nan, 22, 60],\n",
        "    'Income': [50000, 120000, 80000, 30000, 150000],\n",
        "    'City': ['NYC', 'London', 'Paris', 'NYC', 'London'],\n",
        "    'Target': [0, 1, 0, 1, 1]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "X = df.drop('Target', axis=1)\n",
        "y = df['Target']\n",
        "\n",
        "# --- Step 1: Define Column Groups ---\n",
        "\n",
        "numerical_features = ['Age', 'Income']\n",
        "categorical_features = ['City']\n",
        "\n",
        "# --- Step 2: Define Sub-Pipelines ---\n",
        "\n",
        "# Pipeline for Numerical Data (Impute missing, then scale)\n",
        "numerical_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Pipeline for Categorical Data (Handle missing, then OHE)\n",
        "categorical_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "\n",
        "])\n",
        "\n",
        "# --- Step 3: Combine Pipelines using ColumnTransformer ---\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_pipeline, numerical_features),\n",
        "        ('cat', categorical_pipeline, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# --- Step 4: Final Model Pipeline ---\n",
        "\n",
        "# The final pipeline integrates preprocessing and the model\n",
        "full_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(solver='liblinear'))\n",
        "])\n",
        "\n",
        "# --- Step 5: Training ---\n",
        "\n",
        "# The entire cleaning/scaling/training process is run in one line\n",
        "full_pipeline.fit(X, y)\n",
        "\n",
        "print(\"Pipeline training successful.\")\n",
        "\n",
        "# --- Step 6: Prediction on New Data ---\n",
        "\n",
        "new_data = pd.DataFrame({\n",
        "    'Age': [40, np.nan],\n",
        "    'Income': [60000, 95000],\n",
        "    'City': ['Paris', 'Berlin']\n",
        "})\n",
        "\n",
        "# The exact scaling and imputation rules learned from the training data are applied\n",
        "predictions = full_pipeline.predict(new_data)\n",
        "\n",
        "print(f\"\\nPredictions on new data: {predictions}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
